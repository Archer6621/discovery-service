version: "3.3"
services:

  # Message queue required by Celery for distributed messaging between the workers
  rabbitmq:
     image: rabbitmq:3.8
     restart: always
     environment:
       RABBITMQ_DEFAULT_USER:
       RABBITMQ_DEFAULT_PASS:
       RABBITMQ_PORT: 5672
     expose:
       - 5672

  # Graph database used for discovery
  neo4j:
    image: neo4j:5.3.0
    expose:
      - 7474
      - 7687
    volumes:
      - neo4jdata:/data
    environment:
      NEO4J_AUTH:

  # Fix ownership of data volumes 
  fix_data_ownership:
    image: busybox:1.32
    command:
    - chown
    - -vR
    - '1000:1000'
    - /data
    - /celerydata
    volumes:
      - data:/data
      - celerydata:/celerydata

  # API for public access
  api:
    image: opertusmundi/discovery-backend
    build: 
      context: ./backend
      dockerfile: prod.dockerfile
    ports:
      - "18080:8080"
    depends_on:
      - neo4j
    volumes:
      - data:/data
    command:
    - python
    - -m
    - backend.app
    user: '1000'
    restart: always
    #tty: true
    #privileged: true
    environment:
      PYTHONUNBUFFERED: 1
    env_file:
      - .env

  # Celery worker that does schema matching jobs
  celery-worker:
    image: opertusmundi/discovery-backend
    build: 
      context: ./backend
      dockerfile: prod.dockerfile
    volumes:
      - data:/data
    restart: always
    user: '1000'
    environment: &celery_environment
      PYTHONUNBUFFERED: 1
      DAISY_PRODUCTION:
      DATA_INGESTION_INTERVAL:
      DATA_ROOT_PATH: /data
      VALENTINE_THRESHOLD:
      VALENTINE_ROWS_TO_USE:
      REDIS_HOST:
      REDIS_PORT:
      REDIS_PASSWORD:
      RABBITMQ_HOST:
      RABBITMQ_PORT:
      RABBITMQ_DEFAULT_USER:
      RABBITMQ_DEFAULT_PASS:
      RABBITMQ_VHOST:
    command: 
    - celery 
    - -A 
    - backend.celery 
    - worker 
    - -l 
    - INFO 
    - --concurrency=1
    depends_on:
      - rabbitmq

  # Celery beat, used for scheduling
  celery-beat:
    image: opertusmundi/discovery-backend
    build: 
      context: ./backend
      dockerfile: prod.dockerfile
    volumes:
      - data:/data
      - celerydata:/celerydata
    restart: always
    user: '1000'
    environment: *celery_environment
    command: 
    - celery 
    - -A 
    - backend.celery 
    - beat 
    - -l 
    - INFO
    - -s
    - /celerydata/celerybeat-schedule 
    depends_on:
      - rabbitmq

  # In-memory store with persistence used for storing daisy table metadata and celery task information/statuses
  redis:
    image: redis/redis-stack-server:6.2.6-v2
    environment:
      REDIS_ARGS: >-
        --save 60 1
        --maxmemory 512mb
        --requirepass ${REDIS_PASSWORD}
    expose:
      - 6379
    volumes:
      - redisdata:/data

  # Profiler which determines the primary-key foreign-key constraints
  # FIXME split into containers that start a single process!
  metanome:
    image: opertusmundi/discovery-metanome
    build: 
      context: ./metanome
      dockerfile: Dockerfile
    expose:
    - 8090
    volumes:
    - data:/metanome/backend/WEB-INF/classes/inputData
    command:  sh -c "./start"
    restart: always
    # FIXME remove tty,privileged requirements 
    #tty: true
    #privileged: true
    user: '1000'
    #environment:
      #WAIT_HOSTS: neo4j:7474, neo4j:7687
    env_file:
      - .env

volumes:
  neo4jdata:
  redisdata:
  celerydata:
  data:

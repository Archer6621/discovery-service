version: "3.3"
services:

  # Message queue required by Celery for distributed messaging between the workers
  rabbitmq:
     image: rabbitmq:3.8
     restart: always
     environment:
       RABBITMQ_DEFAULT_USER:
       RABBITMQ_DEFAULT_PASS:
       RABBITMQ_PORT: 5672
     expose:
       - 5672

  # Graph database used for discovery
  neo4j:
    image: neo4j:5.3.0
    expose:
    - 7474
    - 7687
    volumes:
    - neo4jdata:/data
    environment:
      NEO4J_AUTH:

  # Fix ownership of data volumes 
  fix_data_ownership:
    image: busybox:1.32
    command:
    - chown
    - -vR
    - '1000:1000'
    - /data
    - /celerydata
    volumes:
    - data:/data
    - celerydata:/celerydata

  # API for public access
  api:
    image: opertusmundi/discovery-backend
    build: 
      context: ./backend
      dockerfile: prod.dockerfile
    ports:
    - "18080:8080"
    volumes:
    - data:/data:ro
    command:
    - python
    - -m
    - backend.app
    user: '1000'
    restart: always
    environment: &backend_env
      PYTHONUNBUFFERED: 1
      DAISY_PRODUCTION:
      DATA_INGESTION_INTERVAL:
      DATA_ROOT_PATH: /data
      VALENTINE_THRESHOLD:
      VALENTINE_ROWS_TO_USE:
      REDIS_HOST:
      REDIS_PORT:
      REDIS_PASSWORD:
      RABBITMQ_HOST:
      RABBITMQ_PORT:
      RABBITMQ_DEFAULT_USER:
      RABBITMQ_DEFAULT_PASS:
      RABBITMQ_VHOST:
      NEO4J_AUTH:
      NEO4J_ADDRESS:
      METANOME_API_ADDRESS:
    depends_on:
    - neo4j

  # Celery worker that does schema matching jobs
  celery-worker:
    image: opertusmundi/discovery-backend
    build: 
      context: ./backend
      dockerfile: prod.dockerfile
    volumes:
    - data:/data:ro
    restart: always
    user: '1000'
    environment: *backend_env
    command: 
    - celery 
    - -A 
    - backend.celery 
    - worker 
    - -l 
    - INFO 
    - --concurrency=1
    depends_on:
    - rabbitmq
    - redis
    - neo4j

  # Celery beat, used for scheduling
  celery-beat:
    image: opertusmundi/discovery-backend
    build: 
      context: ./backend
      dockerfile: prod.dockerfile
    volumes:
      - celerydata:/celerydata
    restart: always
    user: '1000'
    environment: *backend_env
    command: 
    - celery 
    - -A 
    - backend.celery 
    - beat 
    - -l 
    - INFO
    - -s
    - /celerydata/celerybeat-schedule 
    depends_on:
    - rabbitmq

  # In-memory store with persistence used for storing daisy table metadata and celery task information/statuses
  redis:
    image: redis/redis-stack-server:6.2.6-v2
    environment:
      REDIS_ARGS: >-
        --save 60 1
        --maxmemory 512mb
        --requirepass ${REDIS_PASSWORD}
    expose:
    - 6379
    volumes:
    - redisdata:/data

volumes:
  neo4jdata:
  redisdata:
  celerydata:
  data:
